import os
import json
import librosa
import shutil
from dotenv import load_dotenv
from pydub import AudioSegment
from groq import Groq
from faster_whisper import WhisperModel
from datetime import datetime
from fastapi import FastAPI, Query, HTTPException, UploadFile, File, BackgroundTasks
from starlette.responses import JSONResponse

load_dotenv()
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))

api_key = os.getenv("GROQ_API_KEY")
print("üîë Loaded key from env:", api_key[:10] if api_key else None)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏≤‡πÑ‡∏´‡∏°

if not api_key:
    raise RuntimeError("‚ùå GROQ_API_KEY not found. Check .env location or syntax")

client = Groq(api_key=api_key)
print("üìÅ .env path:", os.path.join(os.path.dirname(__file__), ".env"))
print("üîç Current working dir:", os.getcwd())

ASR_MODEL_NAME = "base"
ASR_COMPUTE_TYPE = "int8" # "float16" ‡∏´‡∏£‡∏∑‡∏≠ "int8" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß

LLM_MODEL_NAME = "llama-3.3-70b-versatile"

# Prompt ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ Whisper ‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
PROMPT_FOR_FILLERS = """
‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Ñ‡∏á‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏ß‡πâ ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤ ‡πÄ‡∏≠‡πà‡∏≠ ‡πÅ‡∏ö‡∏ö‡∏ß‡πà‡∏≤ ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ô‡∏∞‡∏Ñ‡∏∞
"""

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢ (Filler Words) ‡∏ó‡∏µ‡πà‡∏Ç‡πà‡∏≠‡∏¢‡∏à‡∏∞‡∏ô‡∏±‡∏ö
THAI_FILLER_WORDS = [
    "‡∏≠‡πà‡∏≤", "‡πÄ‡∏≠‡πà‡∏≠", "‡πÅ‡∏ö‡∏ö‡∏ß‡πà‡∏≤", "‡∏Ñ‡∏∑‡∏≠", "‡πÅ‡∏ö‡∏ö", "‡∏Å‡πá‡∏ô‡∏∞",
    "‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡∏ö", "‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°", "‡πÉ‡∏ä‡πà‡∏õ‡πà‡∏∞", "‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏ô‡∏∞‡∏Ñ‡∏∞", "‡∏≠‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏≠‡∏∞‡∏Ñ‡πà‡∏∞"
]

app = FastAPI()

UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# --- Global Model Cache ---
asr_model = None

def get_asr_model():
    """Loads the ASR model into memory if it's not already loaded."""
    global asr_model
    if asr_model is None:
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ASR ({ASR_MODEL_NAME}) ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å...")
        asr_model = WhisperModel(ASR_MODEL_NAME, device="cpu", compute_type=ASR_COMPUTE_TYPE)
    return asr_model

def convert_to_wav(source_path: str) -> str:
    """
    Converts an audio/video file to a temporary WAV file for analysis.
    Returns the path to the new WAV file.
    """
    print(f"Converting {source_path} to WAV format...")
    try:
        audio = AudioSegment.from_file(source_path)
        # Create a temporary path for the WAV file
        base, _ = os.path.splitext(source_path)
        wav_path = f"{base}_temp.wav"
        # Export as WAV
        audio.export(wav_path, format="wav")
        print(f"Successfully converted to {wav_path}")
        return wav_path
    except Exception as e:
        print(f"Error during audio conversion: {e}")
        # Re-raise the exception to be caught by the background task handler
        raise

def transcribe_audio(file_path, model: WhisperModel):
    """
    ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ü‡∏•‡πå audio ‡πÄ‡∏õ‡πá‡∏ô text ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ faster-whisper (Quantized)
    """
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ü‡∏•‡πå: {file_path}...")

    segments, info = model.transcribe(
        file_path,
        beam_size=5,
        language="th",
        initial_prompt=PROMPT_FOR_FILLERS
    )

    full_transcript = "".join([seg.text for seg in segments])

    # ‡πÉ‡∏ä‡πâ librosa.get_duration ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå .wav
    try:
        duration_seconds = librosa.get_duration(path=file_path)
    except Exception as e:
        print(f"Librosa failed to get duration for {file_path}: {e}")
        duration_seconds = info.duration if hasattr(info, "duration") else 0

    print("--- Transcript (‡∏ú‡∏•‡∏î‡∏¥‡∏ö‡∏à‡∏≤‡∏Å Whisper) ---")
    print(full_transcript)
    print("--------------------------------------")

    return full_transcript, duration_seconds

def analyze_presentation(transcript, duration_seconds):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Transcript ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LLM (Groq) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏•‡∏∞ Feedback
    """
    print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á Transcript ‡πÑ‡∏õ‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå...")

    words = transcript.split()
    total_words = len(words)
    duration_minutes = duration_seconds / 60
    words_per_minute = total_words / duration_minutes if duration_minutes > 0 else 0

    # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢
    filler_counts = {}
    total_fillers = 0
    for filler in THAI_FILLER_WORDS:
        count = transcript.lower().count(filler)
        if count > 0:
            filler_counts[filler] = count
            total_fillers += count

    # 2. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ
    current_date_str = datetime.now().strftime("%d %B %Y")

    # 3. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç System Prompt ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á Format ‡πÉ‡∏´‡∏°‡πà
    system_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏Ñ‡πâ‡∏ä‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ (Presentation Coach) ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö
‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô JSON Object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏î‡πÜ ‡∏ô‡∏≠‡∏Å JSON

‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤:
{{
    "score": <float, 0-100>,
    "analysis_date": "<string, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå, ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö 'DD Month YYYY'>",
    "strengths": [
    "<string, ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà 1>",
    "<string, ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà 2>"
    ],
    "improvements": [
    "<string, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ó‡∏µ‡πà 1>",
    "<string, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ó‡∏µ‡πà 2>"
    ]
}}

‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (score):
- 100: ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö, ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô, ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏û‡∏≠‡∏î‡∏µ
- 85-95: ‡∏î‡∏µ‡∏°‡∏≤‡∏Å, ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
- 70-84: ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á, ‡∏û‡∏π‡∏î‡πÄ‡∏£‡πá‡∏ß/‡∏ä‡πâ‡∏≤‡πÑ‡∏õ, ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢
- < 70: ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏î‡πà‡∏ß‡∏ô, ‡∏à‡∏±‡∏ö‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å
    """

    user_prompt = f"""
‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢

--- ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå) ---
‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {current_date_str}
‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î (WPM): {words_per_minute:.2f} ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ô‡∏≤‡∏ó‡∏µ
(‡πÄ‡∏Å‡∏ì‡∏ë‡πå WPM ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: 130-160 WPM)
‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_fillers} ‡∏Ñ‡∏≥
‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢: {json.dumps(filler_counts, ensure_ascii=False)}

--- Transcript ---
{transcript}
---

‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
(‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ keys: "score", "analysis_date", "strengths", "improvements")
    """

    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            model=LLM_MODEL_NAME,
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        response_json_str = chat_completion.choices[0].message.content

        analysis_result = json.loads(response_json_str)

        return analysis_result

    except Exception as e:
        print(f"‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏∞ dude : {e}")
        # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ error ‡πÉ‡∏ô format ‡∏ó‡∏µ‡πà frontend ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏û‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ
        return {
            "error": str(e),
            "score": 0,
            "analysis_date": current_date_str,
            "strengths": [],
            "improvements": ["‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå LLM"]
        }

def run_analysis_in_background(file_path: str, sanitized_filename: str):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ô‡πÉ‡∏ô background ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå .json
    """
    print(f"Background task started for: {sanitized_filename}")
    model = get_asr_model()
    wav_file_path = None
    try:
        # Convert the uploaded file to a processable WAV format first
        wav_file_path = convert_to_wav(file_path)

        transcript, duration = transcribe_audio(wav_file_path, model)
        if transcript:
            analysis_data = analyze_presentation(transcript, duration)
            cache_path = os.path.join(UPLOAD_DIR, f"{sanitized_filename}.json")
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=4)
            print(f"Background task finished for: {sanitized_filename}")

    except Exception as e:
        print(f"Error during background analysis for {sanitized_filename}: {e}")
        # If an error occurs, create a JSON file with the error message
        # This helps the frontend know that the process failed.
        error_data = {
            "status": "error",
            "detail": str(e)
        }
        cache_path = os.path.join(UPLOAD_DIR, f"{sanitized_filename}.json")
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(error_data, f, ensure_ascii=False, indent=4)

@app.post("/uploadfile/")
async def create_upload_file(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    """
    ‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á, ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å, ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå JSON ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
    """
    # Sanitize filename to prevent directory traversal issues and spaces
    sanitized_filename = os.path.basename(file.filename.replace(" ", "_"))
    file_path = os.path.join(UPLOAD_DIR, sanitized_filename)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    try:
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        print(f"File '{file.filename}' uploaded and saved as '{sanitized_filename}'")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to save file: {e}")

    # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô analysis ‡πÉ‡∏ô background
    background_tasks.add_task(run_analysis_in_background, file_path, sanitized_filename)

    # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß
    return JSONResponse(
        content={"message": "Analysis started in background", "filename": sanitized_filename}
    )

@app.get("/status/{filename}")
async def get_analysis_status(filename: str):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå .json ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß, ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏Ñ‡∏∑‡∏≠‡∏¢‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏¢‡∏π‡πà
    """
    cache_file_path = os.path.join(UPLOAD_DIR, f"{filename}.json")

    if os.path.exists(cache_file_path):
        with open(cache_file_path, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        if analysis_data.get("status") == "error":
            return JSONResponse(content=analysis_data)
        else:
            return JSONResponse(content={"status": "complete", "data": analysis_data})
    else:
        return JSONResponse(content={"status": "processing"})

@app.get("/uploadfile/")
async def get_analysis_by_filename(filename: str = Query(..., description="‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")):
    """
    ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
    (‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å)
    """
    cache_file_path = os.path.join(UPLOAD_DIR, f"{filename}.json")
    audio_file_path = os.path.join(UPLOAD_DIR, filename)

    if os.path.exists(cache_file_path):
        print(f"Found cached analysis for '{filename}'. Reading from cache.")
        with open(cache_file_path, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        return JSONResponse(content=analysis_data)

    if not os.path.exists(audio_file_path):
        raise HTTPException(status_code=404, detail=f"File '{filename}' not found.")

    raise HTTPException(status_code=425, detail="Analysis is still in progress. Please try again later.")