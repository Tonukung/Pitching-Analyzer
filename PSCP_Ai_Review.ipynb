{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCsEv89Bd9On",
        "outputId": "8c122202-75da-471c-8b11-8ed7035a1574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Collecting groq\n",
            "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.5.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Downloading faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, groq, faster-whisper\n",
            "Successfully installed av-16.0.1 coloredlogs-15.0.1 ctranslate2-4.6.0 faster-whisper-1.2.0 groq-0.33.0 humanfriendly-10.0 onnxruntime-1.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faster-whisper librosa groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mjSsW7CKOZH7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NFC7-vfdOZdq"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJqCBvl7FwdK",
        "outputId": "cdac6d72-ab0b-4c5e-fb91-8395d75336f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "กำลังโหลดโมเดล ASR (large-v3)...\n",
            "กำลังถอดเสียงไฟล์: /content/EV Hack Video.mp4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2308141347.py:43: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
            "\tThis alias will be removed in version 1.0.\n",
            "  duration_seconds = librosa.get_duration(filename=file_path)\n",
            "/tmp/ipython-input-2308141347.py:43: FutureWarning: PySoundFile failed. Trying audioread instead.\n",
            "\tAudioread support is deprecated in librosa 0.10.0 and will be removed in version 1.0.\n",
            "  duration_seconds = librosa.get_duration(filename=file_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Transcript (ผลดิบจาก Whisper) ---\n",
            "สวัสดีค่ะ พวกเรามาจากทีม by4dad ขี่ไปโซ่หลุด ทุกท่านลองในภาพตามดูเลยค่ะคุณกําลังขับรถอีบีออกไปทํางานตอนเช้า ทุกอย่างก็ดูร่ามเรื่องดีจนกระทั่งคุณสังเกตเห็นว่าแบตคุณใกล้หมดแล้ว คุณก็เลยลองเปิดแอปแผนที่เพื่อแบบหาสถานีชาร์จที่ใกล้ที่สุด แต่ข้อมูลไม่อัปเดต บางที่เต็ม บางที่ใช้ไม่ได้ทําให้คุณต้องวนหาจุดที่ชาร์จได้ ซึ่งคุณก็ต้องเสียทั้งเวลา ลองถึงแบตด้วยแบตคุณก็มีน้อยแล้ว ทําให้คุณต้องเสียเวลา ทั้งเสียแบตเพิ่มไปอีกหรือ..วันหนึ่ง.. you break in the trainแต่ว่าบ้างเอิญเกิดปัญหาการทางคุณก็เลยกำลังหาศูนย์ซ่อมแต่ nuancedแต่คุณก็ไม่แน่ใจว่าที่ไหนมันจะไว้ใจได้หรือค่าซ่อมจะสูงแค่ไหนหรือต้องรอคิวนันเท่านั้นทำให้คุณต้องเสี่ยเวลาหาศูนย์ซ่อมเองหรือการณีที่คุณกำลังจะชาร์จรถ EVแต่คุณไม่รู้ว่ามีค่าจะจ่ายประมาณเท่าไหร่เพราะแต่อาสารนี้ก็คิดราคาต่างกันบางที่แพงกว่าได้คิดหรือบางที่ไม่มีเรทราคาให้ดูเลยทำให้คุณต้องมาลุ้นตอนที่ถึงที่ชาร์จไฟจริงก่อนหรือว่าอาจจะต้องรอลุ้นอีกทีคือตอนบินออกเลยหรือคุณอยากจะช่วยลดบุญรับพิษและสับสุนพลังงานสะอาดแต่คุณไม่รู้ว่าทุกกิโลเมตรที่คุณขับ EV นั้นจะไปช่วยลดคาร์บอนได้มากน้อยแค่ไหนซึ่งทำให้คุณได้มีแน่นใจในการเปลี่ยนมาใช้ยันทร์ภาระ EVและถ้ามีแอปที่ช่วยแก้ปัญหาทุกข้อเหล่านี้ล่ะแอปที่จะช่วยให้การใช้ EV สนุกขึ้นคุ้มค่าขึ้นและมีประโยชน์สำหรับทุกคนแอปของพวกเรามีชื่อว่า Charge Green ครับโดยมีอักหลัก ๆ 4 ฟีเจอร์1. EV Care & Service Finderมีการแนะนำศูนย์ซ่อม EV ที่ใกล้ที่สุดพร้อมรีวิวมีแนะนำที่เช่าแบตเตอรี่ร้านอุปกรณ์แต่งรถ EVและระบบจองคิวซ่อมผ่านแอป2. Smart Energy & Cost Calculatorแสดงปริมาณแบตที่ยังเหลือพลังงานที่ใช้ อุณหภูมิของแบตรวมถึงระยะทางที่ขับได้โดยประเมินจากความเร็วที่ใช้มีระบบเตือนว่าแบตใกล้หมดแนะนำสถานีจุดชาร์จและคำนวณค่าไฟฟ้าที่ชาร์จโดยประมาณ3. Carbon Credit & Reward Systemนำระยะทางที่ผู้ใช้เดินทางมามาแลกเป็นแต้มคะแนนจากการลด Carbon Creditโดยสามารถนำคะแนนที่แรกเป็นส่วนลดล้านพาร์ทเนอร์ได้มีระบบ Leader Boardเพื่อกระตุ้นให้ผู้ใช้อยากได้แต้มมากขึ้น4. NFCสามารถสแกน NFC เปลี่ยนแบตได้มีบอกประวัติการเปลี่ยนแบตครับพวกเราหารายได้จาก Subscription เป็นหลักโดยตั้งราคาอยู่ที่199 บาทต่อเดือนและ 1,999 บาทต่อปีมีการให้ผู้ใช้สามารถทดลองใช้ได้ฟรี 1 เดือนเพื่อดึงดูดผู้ใช้มีรายได้จากค่าคอมมิชชั่นกับศูนย์ซ่อม ร้านขายอุปกรณ์แต่งรถและร้านเช่าแบตเตอรี่รวมถึงได้รายได้จากการขายข้อมูลคาร์บอนเครดิตให้แก่องค์กรหรือบริษัทด้านพลังงานและสิ่งแวดล้อมBusiness Board of CanvasKey Partners จะมีผู้ผลิตแบตเตอรี่เยอะแย่งอันพิธารณะไฟฟ้า เช่น e-bike หรือ e-scooterบริษัทด้านพลังงาน สำหรับการคำนวณและขายคาร์บอนเครดิตศูนย์ซ่อม หรือร้านค้า ขายอุปกรณ์แต่งรถร้านเช่าแบตเตอรี่ผู้ให้บริการการเก็บข้อมูลและการประวัติผลเช่น ที่เป็น Cloud System Providerพันธวิตด้านการตลาดเพื่อประมูลแอปและสร้างการรู้จักKey Activity การพัฒนาและประมูลรักษาแอปพลิเคชันUpdate Feature ปรับปลูกประสิทธิภาพการสร้างและรักษาความสัมพันธ์กับพันธวิตเช่น ศูนย์ซ่อม ร้านเช่าแบตเตอรี่ อุปกรณ์แต่งรถKey Resource หารข้อมูลของพันธวิตเช่น ศูนย์ซ่อม ร้านเช่าแบตเตอรี่ อุปกรณ์แต่งรถทีมงานพัฒนาแอปพลิเคชันValue Propositionsช่วยลดคาร์บอนและค่าใช้จ่ายการเดินทางบริยะทางที่ใช้แสดงว่าต้องใช้แบตหรือไฟเท่าไหร่ในการเดินทางคำนวณคาร์บอนเครดิตที่ลดได้จากการใช้ยานปลาดน้ำไฟฟ้าเป็นแต้มใน Leaderboard ซึ่งสามารถแลกไปส่วนรถได้ระบบแนะนำศูนย์ซ่อมที่เช่าแบตอุปกรณ์แต่งรถที่สะดวกและใกล้ที่สุดระบบติดตามการผ่าผ่านแคลอรี่เช่น กรณีปั่นจักรยานไฟฟ้าCustomer Relationshipsแอปแบบ Free Styleเปิดให้ใช้ฟรี 1 เดือนแล้วค่อยจ่ายโปรโมชั่นและส่วนลดสำหรับสมาชิกกิจการสะสมแต้งคาร์บอนคิลิตในการชวนเพื่อนกิจกรรมช่วยสังคมต่าง ๆChannelsGoogle Play Storeหรือ Apple App StoreSocial Mediaเพื่อประมวลแอปการสร้างคอนเทนต์เกี่ยวกับการเดินทางที่ยังยืนCustomer Segmentผู้ใช้ยานภาษาไฟฟ้าผู้ที่รักโลกหรือสิ่งแวดล้อมผู้ที่ใช้บริการศูนย์ซ่อมหรือร้านขายอุปกรณ์แต่งรถหรือร้านช่างแบตเตอรี่องค์กรหรือบริษัทด้านพลังงานและสิ่งแวดล้อมCore Structureต้นทุนในการพัฒนาและบำรุงรักษาแอปทีมพัฒนาอัปเดตฟีเจอร์ใหม่ ๆค่าใช้จ่ายในการเก็บข้อมูลและประมวลผลเช่น การใช้คาวเซอร์วิสหรือ Data Storageการตลาดและการโปรโมทแอปเช่น การโฆษณาออนไลน์หรือการเสียค่าใช้บริการจากพันธมิตรRevenue StreamSubscription Feeรายเดือนหรือรายปีสำหรับฟีเจอร์การขายข้อมูลให้กับบริษัทหรือองค์กรด้านพลังงานและสิ่งแวดล้อมAffiliate Feeค่าคอมมิชชั่นหรือร้านขายอุปกรณ์แต่งรถร้านช่วยแบตเตอรี่และส่วนซ่อมที่มีในแอปEnvironmentมีการยึดหลักตาม SDGข้อที่ 7การเข้าถึงพลังงานสะอาดและการเข้าถึงการชาร์จไฟฟ้าสำหรับจักรยานไฟฟ้าในเมืองข้อที่ 11สร้างเมืองยั่งยืนผ่านระบบการแรกเปลี่ยนแบตเตอรี่ไฟฟ้าและสถานีชาร์จอัชริยะข้อที่ 13\n",
            "--------------------------------------\n",
            "กำลังส่ง Transcript ไปให้ LLM วิเคราะห์...\n",
            "\n",
            "\n",
            "ผลการวิเคราะห์ (JSON Output)\n",
            "{\n",
            "  \"file_name\": \"/content/EV Hack Video.mp4\",\n",
            "  \"analysis\": {\n",
            "    \"communication_clarity_score\": 82.5,\n",
            "    \"good_points\": [\n",
            "      \"การนำเสนอที่มีโครงสร้างชัดเจนและครอบคลุมฟีเจอร์ของแอปพลิเคชัน\",\n",
            "      \"การเน้นถึงคุณค่าของแอปพลิเคชันในการช่วยลดคาร์บอนและค่าใช้จ่ายการเดินทาง\"\n",
            "    ],\n",
            "    \"areas_for_improvement\": [\n",
            "      \"ความเร็วในการพูดที่ช้ากว่าเกณฑ์ที่แนะนำสำหรับภาษาไทย\",\n",
            "      \"การใช้คำฟุ่มเฟือยบางคำที่ไม่จำเป็น\"\n",
            "    ],\n",
            "    \"statistics\": {\n",
            "      \"words_per_minute\": 24.91,\n",
            "      \"total_filler_words\": 3,\n",
            "      \"filler_word_details\": {\n",
            "        \"คือ\": 1,\n",
            "        \"แบบ\": 2\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "(บันทึกผลลัพธ์ลงใน 'analysis_result.json' เรียบร้อย)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import librosa\n",
        "from groq import Groq\n",
        "from faster_whisper import WhisperModel\n",
        "from datetime import datetime # <-- 1. เพิ่ม import นี้\n",
        "\n",
        "ASR_MODEL_NAME = \"large-v3\" \n",
        "ASR_COMPUTE_TYPE = \"float16\" # \"float16\" หรือ \"int8\" เพื่อความเร็ว\n",
        "\n",
        "LLM_MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "# Prompt เอาไว้ให้ Whisper ถอดคำฟุ่มเฟือยออกมา\n",
        "PROMPT_FOR_FILLERS = \"\"\"\n",
        "ต่อไปนี้คือการถอดเสียงการนำเสนอแบบคำต่อคำ\n",
        "กรุณาคงคำฟุ่มเฟือยทั้งหมดไว้ เช่น อ่า เอ่อ แบบว่า นะครับ นะคะ\n",
        "\"\"\"\n",
        "\n",
        "# รายการคำฟุ่มเฟือย (Filler Words) ที่ข่อยจะนับ\n",
        "THAI_FILLER_WORDS = [\n",
        "    \"อ่า\", \"เอ่อ\", \"แบบว่า\", \"คือ\", \"แบบ\", \"ก็นะ\", \n",
        "    \"ที่แบบ\", \"ใช่ไหม\", \"ใช่ป่ะ\", \"นะครับ\", \"นะคะ\", \"อะครับ\", \"อะค่ะ\"\n",
        "]\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    \"\"\"\n",
        "    ถอดเสียงไฟล์ audio เป็น text โดยใช้ faster-whisper (Quantized)\n",
        "    และใช้ Prompt เพื่อบังคับให้ถอดคำฟุ่มเฟือย\n",
        "    \"\"\"\n",
        "    print(f\"กำลังโหลดโมเดล ASR ({ASR_MODEL_NAME})...\")\n",
        "    \n",
        "    # TODO: ควบคุมการโหลดโมเดล (อาจจะโหลดครั้งเดียวนอกฟังก์ชัน)\n",
        "    model = WhisperModel(ASR_MODEL_NAME, device=\"cuda\", compute_type=ASR_COMPUTE_TYPE)\n",
        "    \n",
        "    print(f\"กำลังถอดเสียงไฟล์: {file_path}...\")\n",
        "    segments, info = model.transcribe(\n",
        "        file_path,\n",
        "        beam_size=5,\n",
        "        language=\"th\",\n",
        "        initial_prompt=PROMPT_FOR_FILLERS\n",
        "    )\n",
        "    \n",
        "    full_transcript = \"\".join([seg.text for seg in segments])\n",
        "    \n",
        "    # ใช้ librosa.get_duration(path=...) แทน filename=...\n",
        "    duration_seconds = librosa.get_duration(path=file_path)\n",
        "    \n",
        "    print(\"--- Transcript (ผลดิบจาก Whisper) ---\")\n",
        "    print(full_transcript)\n",
        "    print(\"--------------------------------------\")\n",
        "    \n",
        "    return full_transcript, duration_seconds\n",
        "\n",
        "def analyze_presentation(transcript, duration_seconds):\n",
        "    \"\"\"\n",
        "    วิเคราะห์ Transcript โดยใช้ LLM (Groq) เพื่อให้คะแนนและ Feedback\n",
        "    \"\"\"\n",
        "    print(\"กำลังส่ง Transcript ไปให้ LLM วิเคราะห์...\")\n",
        "    \n",
        "    words = transcript.split()\n",
        "    total_words = len(words)\n",
        "    duration_minutes = duration_seconds / 60\n",
        "    words_per_minute = total_words / duration_minutes if duration_minutes > 0 else 0\n",
        "    \n",
        "    # นับคำฟุ่มเฟือย\n",
        "    filler_counts = {}\n",
        "    total_fillers = 0\n",
        "    for filler in THAI_FILLER_WORDS:\n",
        "        count = transcript.lower().count(filler)\n",
        "        if count > 0:\n",
        "            filler_counts[filler] = count\n",
        "            total_fillers += count\n",
        "    \n",
        "    # 2. เพิ่มวันที\n",
        "    current_date_str = datetime.now().strftime(\"%d %B %Y\")\n",
        "            \n",
        "    # 3. แก้ไข System Prompt ให้ตรง Format ใหม่\n",
        "    system_prompt = f\"\"\"\n",
        "คุณคือโค้ชด้านการนำเสนอ (Presentation Coach) ที่เชี่ยวชาญและให้คำแนะนำที่สร้างสรรค์\n",
        "หน้าที่ของคุณคือวิเคราะห์สคริปต์การนำเสนอและสถิติที่ได้รับ\n",
        "และให้ผลลัพธ์กลับมาเป็น JSON Object เท่านั้น ห้ามมีข้อความอื่นใดๆ นอก JSON\n",
        "\n",
        "รูปแบบ JSON ที่คุณต้องส่งกลับมา:\n",
        "{{\n",
        "  \"score\": <float, 0-100>,\n",
        "  \"analysis_date\": \"<string, วันที่วิเคราะห์, รูปแบบ 'DD Month YYYY'>\",\n",
        "  \"strengths\": [\n",
        "    \"<string, จุดแข็งที่ 1>\",\n",
        "    \"<string, จุดแข็งที่ 2>\"\n",
        "  ],\n",
        "  \"improvements\": [\n",
        "    \"<string, ข้อควรปรับปรุงที่ 1>\",\n",
        "    \"<string, ข้อควรปรับปรุงที่ 2>\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "เกณฑ์การให้คะแนน (score):\n",
        "- 100: สมบูรณ์แบบ, ชัดเจน, ไม่มีคำฟุ่มเฟือย, ความเร็วพอดี\n",
        "- 85-95: ดีมาก, อาจมีคำฟุ่มเฟือยเล็กน้อย\n",
        "- 70-84: ปานกลาง, พูดเร็ว/ช้าไป, มีคำฟุ่มเฟือย\n",
        "- < 70: ต้องปรับปรุงด่วน, จับใจความยาก\n",
        "    \"\"\"\n",
        "    \n",
        "    user_prompt = f\"\"\"\n",
        "ช่วยวิเคราะห์การนำเสนอครั้งนี้ให้หน่อย\n",
        "\n",
        "--- สถิติ (สำหรับใช้ประกอบการวิเคราะห์) ---\n",
        "วันที่ปัจจุบัน: {current_date_str}\n",
        "ความเร็วในการพูด (WPM): {words_per_minute:.2f} คำต่อนาที\n",
        "(เกณฑ์ WPM ที่ดีสำหรับภาษาไทย: 130-160 WPM)\n",
        "จำนวนคำฟุ่มเฟือยทั้งหมด: {total_fillers} คำ\n",
        "รายละเอียดคำฟุ่มเฟือย: {json.dumps(filler_counts, ensure_ascii=False)}\n",
        "\n",
        "--- Transcript ---\n",
        "{transcript}\n",
        "---\n",
        "\n",
        "โปรดวิเคราะห์และส่งผลลัพธ์เป็น JSON ตามรูปแบบที่กำหนดเท่านั้น\n",
        "(ต้องมี keys: \"score\", \"analysis_date\", \"strengths\", \"improvements\")\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        client = Groq()\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            model=LLM_MODEL_NAME,\n",
        "            temperature=0.3,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        \n",
        "        response_json_str = chat_completion.choices[0].message.content\n",
        "        \n",
        "        analysis_result = json.loads(response_json_str)\n",
        "        \n",
        "        return analysis_result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"เรียก LLM ไม่ได้อะ dude : {e}\")\n",
        "        # คืนค่า error ใน format ที่ frontend อาจจะพออ่านได้\n",
        "        return {\n",
        "            \"error\": str(e), \n",
        "            \"score\": 0, \n",
        "            \"analysis_date\": current_date_str, \n",
        "            \"strengths\": [], \n",
        "            \"improvements\": [\"เกิดข้อผิดพลาดในการวิเคราะห์ LLM\"]\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # เปลี่ยนเป็นชื่อไฟล์ของคุณ\n",
        "    audio_file = \"/content/EV Hack Video.mp4\" \n",
        "\n",
        "    if not os.path.exists(audio_file):\n",
        "        print(f\"!!! [Error เเล้วพรี่] !!!\")\n",
        "        print(f\"ไม่เจอไฟล์ '{audio_file}' เช็คดีๆดิ๊\")\n",
        "        return\n",
        "\n",
        "    transcript, duration = transcribe_audio(audio_file)\n",
        "    \n",
        "    if not transcript:\n",
        "        print(\"ถอดเสียงบ่ได้\")\n",
        "        return\n",
        "\n",
        "    analysis_data = analyze_presentation(transcript, duration)\n",
        "    \n",
        "    if analysis_data:\n",
        "        print(\"\\n\\nผลการวิเคราะห์ (JSON Output ที่แก้ไขแล้ว)\")\n",
        "        \n",
        "        # 4. แก้ไข Output JSON ให้เป็นแบบ Flat (ไม่ซ้อน)\n",
        "        # โดยการรวม filename เข้ากับผลลัพธ์จาก analysis_data\n",
        "        \n",
        "        # ใช้ os.path.basename เพื่อเอาแค่ชื่อไฟล์ ไม่เอา path เต็ม\n",
        "        final_json_output = {\n",
        "            \"filename\": os.path.basename(audio_file)\n",
        "        }\n",
        "        \n",
        "        # .update() จะเอากุญแจทั้งหมดจาก analysis_data มารวมใน final_json_output\n",
        "        final_json_output.update(analysis_data)\n",
        "        \n",
        "        # ผลลัพธ์ที่ได้จะมีหน้าตาแบบนี้:\n",
        "        # {\n",
        "        #   \"filename\": \"EV Hack Video.mp4\",\n",
        "        #   \"score\": 85.0,\n",
        "        #   \"analysis_date\": \"30 October 2025\",\n",
        "        #   \"strengths\": [...],\n",
        "        #   \"improvements\": [...]\n",
        "        # }\n",
        "        \n",
        "        print(json.dumps(final_json_output, indent=2, ensure_ascii=False))\n",
        "        \n",
        "        with open(\"analysis_result.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(final_json_output, f, indent=2, ensure_ascii=False)\n",
        "        print(\"\\n(บันทึกผลลัพธ์ลงใน 'analysis_result.json' เรียบร้อย)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
